@misc{Lauritzen_2019,
  title     = {Tal og Lineær Algebra 2019 4 Matricer},
  url       = {https://data.math.au.dk/interactive/lintrans/Chapters/vektorerogmatricer.html},
  journal   = {Tal og Lineær Algebra 2019},
  publisher = {Matematisk Institut, Aarhus Universitet},
  author    = {Niels Lauritzen and Marcel B{\"o}kstedt},
  organization = {Matematisk Institut, Aarhus Universitet},
  year      = {2019}
}

@misc{Simonson_2015,
  title     = {Matrix Multiplication Made Easy},
  url       = {https://blogs.ams.org/mathgradblog/2015/10/19/matrix-multiplication-easy/},
  journal   = {AMS Math Grad Blog},
  publisher = {Matematisk Institut, Aarhus Universitet},
  author    = {Simonson, Matthew},
  year      = {2015},
  month     = {10},
  organization = {American Mathematical Society}
}

@misc{St_Clair_2021,
  title     = {Explainer: What is a neuron?},
  url       = {https://www.snexplores.org/article/explainer-what-is-a-neuron},
  journal   = {Science News Explores},
  publisher = {Science News Explores},
  author    = {St. Clair, Bryn},
  year      = {2021},
  month     = {4},
  organization = {Science News}
}

@misc{LeCun_1994,
  title     = {MNIST handwritten digit database},
  url       = {https://yann.lecun.com/exdb/mnist/},
  journal   = {Courant Institute NYU, Google Labs, Microsoft Research},
  publisher = {Courant Institute NYU, Google Labs, Microsoft Research},
  author    = {LeCun, Yann and Cortes, Corinna and Burges, Christopher J.C.},
  year      = {1994},
  organization = {Courant Institute NYU, Google Labs, Microsoft Research}
}

@misc{IBM_2021,
  title     = {What is Gradient Descent? | IBM},
  url       = {https://www.ibm.com/topics/gradient-descent},
  journal   = {IBM},
  publisher = {IBM},
  author    = {IBM},
  year      = {1994},
  organization = {IBM}
}

@misc{Sanderson_2017,
  title     = {Gradient descent, how neural networks learn},
  url       = {https://www.3blue1brown.com/lessons/gradient-descent},
  journal   = {3Blue1Brown},
  publisher = {Sanderson, Grant},
  author    = {Sanderson, Grant},
  year      = {2017},
  organization = {3Blue1Brown}
}

@misc{Khodabakhsh,
  author       = {Hojjatk Khodabakhsh},
  organization = {Kaggle},
  title        = {Read MNIST Dataset | Kaggle},
  year         = {2019},
  month        = {1},
  day          = {12},
  url          = {https://www.kaggle.com/code/hojjatk/read-mnist-dataset},
}

@misc{Nielsen_2019a,
  title     = {Using neural nets to recognize handwritten digits},
  url       = {http://neuralnetworksanddeeplearning.com/chap1.html},
  journal   = {Neural Networks and Deep Learning},
  publisher = {Nielsen, Michael},
  author    = {Nielsen, Michael},
  year      = {2019}
}

@misc{Nielsen_2019b,
  title     = {How the backpropagation algorithm works},
  url       = {http://neuralnetworksanddeeplearning.com/chap2.html},
  journal   = {Neural Networks and Deep Learning},
  publisher = {Nielsen, Michael},
  author    = {Nielsen, Michael},
  year      = {2019},
}

@misc{Kirsanov_2024,
  title     = {The Most Important Algorithm in Machine Learning},
  url       = {https://www.youtube.com/watch?v=SmZmBKc7Lrs},
  journal   = {YouTube},
  publisher = {Kirsanov, Artem},
  author    = {Kirsanov, Artem},
  year      = {2024}
}

@misc{Kumar_2024,
  author       = {Ajitesh Kumar},
  organization = {Analytics Yogi},
  title        = {Mean Squared Error vs Cross Entropy Loss Function},
  year         = {2024},
  month        = {May},
  day          = {1},
  url          = {https://vitalflux.com/mean-squared-error-vs-cross-entropy-loss-function/},
  howpublished = {Vitalflux.com},
  organization = {Analytics Yogi}
}

@misc{Stanford_2018,
  title        = {CS231n: Deep Learning for Computer Vision - Lecture 2},
  organization = {Stanford University},
  year         = {2018},
  url          = {https://cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf},
  howpublished = {cs231n.stanford.edu},
  organization = {Stanford University}
}

@misc{mehta2023crossentropy,
  author       = {Shivam Mehta},
  title        = {Deriving categorical cross entropy and softmax},
  year         = {2023},
  month        = {October},
  day          = {1},
  url          = {https://shivammehta25.github.io/posts/deriving-categorical-cross-entropy-and-softmax/},
  urldate      = {2024-12-07}
}

@misc{ma2020cs229,
  author       = {Tengyu Ma and Anand Avati and Kian Katanforoosh and Andrew Ng},
  organization = {Stanford University},
  title        = {CS229 Lecture Notes: Deep Learning},
  year         = {2020},
  url          = {https://cs229.stanford.edu/notes2020spring/cs229-notes-deep_learning.pdf},
}

@misc{keita2023backpropagation,
  author       = {Zoumana Keita},
  title        = {Mastering Backpropagation: A Comprehensive Guide for Neural Networks},
  year         = {2023},
  month        = {December},
  day          = {27},
  url          = {https://www.datacamp.com/tutorial/mastering-backpropagation},
  urldate      = {2024-12-07},
  publisher    = {DataCamp},
  organization = {DataCamp}
}

@misc{kurbiel2021softmax,
  author       = {Thomas Kurbiel},
  title        = {Derivative of the Softmax Function and the Categorical Cross-Entropy Loss},
  year         = {2021},
  month        = {April},
  day          = {22},
  url          = {https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1},
  urldate      = {2024-12-08},
  publisher    = {Towards Data Science},
  organization = {Towards Data Science}
}

@misc{verma2020neuralnet,
  author       = {Akshaj Verma},
  title        = {Building A Neural Net from Scratch Using R - Part 1},
  year         = {2020},
  month        = {July},
  day          = {20},
  url          = {https://rviews.rstudio.com/2020/07/20/shallow-neural-net-from-scratch-using-r-part-1/},
  urldate      = {2024-12-08},
  publisher    = {R Views},
  organization = {R Views}
}

@misc{smith2024sigmoid,
  author       = {William Smith},
  title        = {Derivative of Sigmoid Function - Simplified Explanation for Better Understanding},
  year         = {2024},
  month        = {February},
  day          = {1},
  url          = {https://www.storyofmathematics.com/derivative-of-sigmoid-function/},
  urldate      = {2024-12-08},
  publisher    = {The Story of Mathematics},
  organization = {The Story of Mathematics}
}

@misc{pranckevicius2015finite,
  title        = {Finite Differences},
  author       = {Aras Pranckevičius},
  organization = {The blog at the bottom of the sea},
  year         = {2015},
  month        = {08},
  day          = {02},
  url          = {https://blog.demofox.org/2015/08/02/finite-differences/},
  publisher    = {blog.demofox.org},
  organization = {The blog at the bottom of the sea}
}


@misc{wagner2022floating,
  title        = {Floating-point numeric types - C\# reference},
  author       = {Bill Wagner},
  organization = {Microsoft Learn},
  year         = {2022},
  month        = {09},
  day          = {29},
  url          = {https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/builtin-types/floating-point-numeric-types},
  publisher    = {learn.microsoft.com},
  organization = {Microsoft Learn}
}

@misc{delclos2021computer,
  title        = {Computer vision — Image recognition via Deep Learning},
  author       = {Yann Delclos},
  organization = {Artificial Intelligence in Plain English},
  year         = {2021},
  month        = {02},
  day          = {07},
  url          = {https://ai.plainenglish.io/computer-vision-image-recognition-via-deep-learning-a144fc45f105},
  note         = {Accessed: 2024-12-10},
  publisher    = {ai.plainenglish.io}
}

Artem Kirsanov


https://cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf
